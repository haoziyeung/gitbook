    ## 1. find
    1.1 按照tag(标签)搜索：
    ```
    find(tagname)        # 直接搜索名为tagname的tag 如：find('head')
    find(list)           # 搜索在list中的tag，如: find(['head', 'body'])
    find(dict)           # 搜索在dict中的tag，如:find({'head':True, 'body':True})
    find(re.compile('')) # 搜索符合正则的tag, 如:find(re.compile('^p')) 搜索以p开头的tag
    find(lambda)         # 搜索函数返回结果为true的tag, 如:find(lambda name: if len(name) == 1) 搜索长度为1的tag
    find(True)           # 搜索所有tag
    ```
    2,按照attrs(属性)搜索:
    ```
    find('id'='xxx')                                  # 寻找id属性为xxx的
    find(attrs={'id':re.compile('xxx'), 'algin':'xxx'}) # 寻找id属性符合正则且algin属性为xxx的
    find(attrs={'id':True, 'algin':None})               # 寻找有id属性但是没有algin属性的
    ```
    ```
    #!/usr/bin/rnv python3
    # -*-coding: utf-8 -*-
    #以豆瓣"编程"分类的一个连接URL为例子开始爬数据ID

    import requests
    from bs4 import BeautifulSoup
    from lxml import etree

    url = 'https://book.douban.com/tag/编程?start=20&type=T'

    def Html_download(url):
        response = requests.get(url)
    #    print(type(response))
    #    print(response.encoding)  #这个是用来查看网页编码的
    #    response.encoding = 'utf-8'  #如果编码有乱码，则可以通过这个定义编码来改变
        content = response.text
        return content

    src = Html_download(url)

    def src_parse(src):
        soup = BeautifulSoup(src, "html.parser")
        total = soup.find_all("li", attrs = {"class": "subject-item"})
    #属性都放着attrs这个字典中，当某个属性的值不是定值的时候，可以使用   '属性名':True  这种方式。
        root = etree.HTML(src)
        print(root)
        tmp = root.xpath('//li[@class="subject-item"]')
        print(tmp)
    src_parse(src)
    ```



